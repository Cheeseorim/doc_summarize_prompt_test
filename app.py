import os
import shutil
import gradio as gr
import requests
# from dotenv import load_dotenv
from openai import OpenAI

# load_dotenv()

upstage_api_key = os.environ.get("UPSTAGE_API_KEY")
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not upstage_api_key:
    raise ValueError("UPSTAGE api keyê°€ ì—†ìŠµë‹ˆë‹¤")
if not openai_api_key:
    raise ValueError("OpenAI api keyê°€ ì—†ìŠµë‹ˆë‹¤")

input_dir = "./docs/input"
parsed_dir = "./docs/parsed"
os.makedirs(input_dir, exist_ok=True)
os.makedirs(parsed_dir, exist_ok=True)

url = "https://api.upstage.ai/v1/document-digitization"
headers = {"Authorization": f"Bearer {upstage_api_key}"}

client = OpenAI(api_key=openai_api_key)

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
DEFAULT_PROMPT = """ë¬¸ì„œë¥¼ ë‹¤ìŒ í˜•ì‹ì— ë”°ë¼ ìš”ì•½í•˜ì„¸ìš”.

## ìš”ì•½ í˜•ì‹    
1. ë¬¸ì„œ ì •ë³´
- ì œëª© :
- ì €ì :
- ì‘ì„± ë‚ ì§œ :
- ì‘ì„± ê¸°ê´€ :

2. ì „ì²´ ìš”ì•½ :

3. ì„¸ë¶€ ìš”ì•½ :


## ìš”ì•½ ë°©ë²•
1. ë¬¸ì„œì˜ ì œëª©ê³¼ ì €ì, ì‘ì„± ë‚ ì§œ ë° ê¸°ê´€ì„ í™•ì¸í•˜ì—¬ "1. ë¬¸ì„œ ì •ë³´"ì— ì ìœ¼ì„¸ìš”. ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ë¹ˆì¹¸ìœ¼ë¡œ ë‘ì„¸ìš”.
2. ë¬¸ì„œì˜ ì „ì²´ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì„¸ìš”.
3. íŒŒì•…í•œ êµ¬ì¡°ë³„ë¡œ í•µì‹¬ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
4. ì¶”ì¶œí•œ í•µì‹¬ ë‚´ìš©ì— ëŒ€í•œ ì„¤ëª…ê³¼ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ 4-5ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
5. í•µì‹¬ ë‚´ìš©ê³¼ ì„¤ëª…, êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ "3. ì„¸ë¶€ ìš”ì•½"ì— ì ìœ¼ì„¸ìš”.
6. ì „ì²´ ë‚´ìš©ì„ 3ê°œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì—¬, "2. ì „ì²´ ìš”ì•½"ì— ë„£ìœ¼ì„¸ìš”.

## ì£¼ì˜ì‚¬í•­
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.
- ë°˜ë“œì‹œ ë¬¸ì„œì— ìˆëŠ” ë‚´ìš©ë§Œì„ í™œìš©í•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.

## ë¬¸ì„œ ë‚´ìš©
{document_content}"""

current_prompt = DEFAULT_PROMPT
current_system_prompt = "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì˜ í™•ì¸í•˜ê³ , ì‚¬ìš©ìê°€ ì „ì²´ì ì¸ ë‚´ìš©ì„ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì„¸ìš”."
current_model = "gpt-5-mini"

def update_prompt(prompt):
    global current_prompt
    current_prompt = prompt if prompt.strip() else DEFAULT_PROMPT
    return "ìš”ì•½ í”„ë¡¬í”„íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."

def update_system_prompt(system_prompt):
    global current_system_prompt
    current_system_prompt = system_prompt if system_prompt.strip() else "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì˜ í™•ì¸í•˜ê³ , ì‚¬ìš©ìê°€ ì „ì²´ì ì¸ ë‚´ìš©ì„ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì„¸ìš”."
    return "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."

def update_model(model):
    global current_system_prompt
    current_model = model if model.strip() else "gpt-5-mini"

def parse_pdf_and_summarize(file):
    try:
        if file is None:
            return "íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

        file_path = file.name
        file_name = os.path.basename(file_path)

        if not file_name.endswith(".pdf"):
            return "PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."

        saved_file_path = os.path.join(input_dir, file_name)
        shutil.copy(file_path, saved_file_path)
        
        with open(saved_file_path, "rb") as f:   
            files = {"document": f}
            data = {
                    "ocr": "force",
                    "model": "document-parse",
                    "output_formats": "['markdown']"
            }
            response = requests.post(url, headers=headers, files=files, data=data)
            result = response.json()
            
        markdown_content = result["content"]["markdown"]
        markdown_file_path = os.path.join(parsed_dir, file_name.replace(".pdf", "_parsed.md"))
        with open(markdown_file_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        
        # í˜„ì¬ ì„¤ì •ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt_template = current_prompt

        # {document_content} í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ ë‚´ìš©ìœ¼ë¡œ ì¹˜í™˜
        if "{document_content}" in prompt_template:
            final_prompt = prompt_template.format(document_content=markdown_content[:8000])
        else:
            # í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìœ¼ë©´ í”„ë¡¬í”„íŠ¸ ëì— ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
            final_prompt = f"{prompt_template}\n\n{markdown_content[:8000]}"
            
        completion = client.chat.completions.create(
            model=current_model,
            messages=[
                {"role": "system", "content": current_system_prompt},
                {"role": "user", "content": final_prompt}]
        )

        summary = completion.choices[0].message.content
        return summary

    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def load_default_prompt():
    return DEFAULT_PROMPT

def load_default_system():
    return "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì˜ í™•ì¸í•˜ê³ , ì‚¬ìš©ìê°€ ì „ì²´ì ì¸ ë‚´ìš©ì„ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•˜ì„¸ìš”."

def load_default_model():
    return "gpt-5-mini"

with gr.Blocks() as demo:
    gr.Markdown("# ğŸ“„ PDF ë¬¸ì„œ íŒŒì‹± ë° ìš”ì•½ ë„êµ¬")
    gr.Markdown("PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ìš”ì•½ì„ ìƒì„±í•˜ì„¸ìš”.")
    gr.Markdown("""### ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ :
    ```
    - gpt-5
    - gpt-5-mini (ê¸°ë³¸)
    - gpt-5-nano
    - gpt-4.1
    - gpt-4.1-mini
    - gpt-4.1-nano
    ```
    """)
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    gr.Markdown("""
    ### ğŸ“‹ ì‚¬ìš©ë²•
    ```
    1. **GPT ëª¨ë¸**: 'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸' ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ì€ gpt-5-minië¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    2. **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**: GPTì˜ ì—­í• ì„ ì •ì˜í•©ë‹ˆë‹¤. "ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°"ë¥¼ í†µí•´ ê¸°ë³¸ê°’ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3. **ìš”ì•½ í”„ë¡¬í”„íŠ¸**: êµ¬ì²´ì ì¸ ìš”ì•½ ë°©ë²•ì„ ì§€ì •í•©ë‹ˆë‹¤. "ê¸°ë³¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°"ë¥¼ í†µí•´ ê¸°ë³¸ê°’ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **{document_content}**: ì´ ë¶€ë¶„ì— ë¬¸ì„œ ë‚´ìš©ì´ ì‚½ì…ë©ë‹ˆë‹¤.
    4. í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•  ê²½ìš°, "ì ìš©" ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤." ë˜ëŠ” "ìš”ì•½ í”„ë¡¬í”„íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."ëŠ” ë©”ì‹œì§€ê°€ ëœ¨ë©´ ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    5. PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  "ì—…ë¡œë“œ & ìš”ì•½"ì„ í´ë¦­í•˜ì„¸ìš”.
    ```

    ### ğŸ’¡ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
    ```
    "ë‹¤ìŒ ë¬¸ì„œì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš”. {document_content}"
    ```
    """)
    
    with gr.Row():
        model_info_input = gr.Textbox(
            label="GPT ëª¨ë¸",
            placeholder=" gpt-5-mini",
            lines=1,
            value=""
        )
    
    with gr.Row():
        model_update_btn = gr.Button("ğŸ¤– ëª¨ë¸ ì ìš©")
        model_load_btn = gr.Button("ğŸ¤– ê¸°ë³¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°")

    # í”„ë¡¬í”„íŠ¸ ì„¤ì • ì„¹ì…˜
    with gr.Row():
        system_prompt_input = gr.Textbox(
            label="ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
            placeholder="GPTì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            lines=3,
            value=""
        )
    
    with gr.Row():
        system_update_btn = gr.Button("ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©")
        system_load_btn = gr.Button("ğŸ¤– ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°")
    
    with gr.Row():
        system_status = gr.Textbox(label="ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒíƒœ", interactive=False)
    
    with gr.Row():
        custom_prompt_input = gr.Textbox(
            label="âœï¸ ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸",
            placeholder="ì›í•˜ëŠ” ë¶„ì„ ë°©ì‹ì„ ì…ë ¥í•˜ì„¸ìš”. {document_content}ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì´ ì‚½ì…ë  ìœ„ì¹˜ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            lines=10,
            value=""
        )
    
    with gr.Row():
        prompt_update_btn = gr.Button("âœï¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì ìš©")
        prompt_load_btn = gr.Button("ğŸ“ ê¸°ë³¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°")
    
    with gr.Row():
        prompt_status = gr.Textbox(label="ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìƒíƒœ", interactive=False)
    
    # íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì„¹ì…˜
    with gr.Row():
        pdf_upload = gr.File(label="ğŸ“‚ PDF íŒŒì¼ ì—…ë¡œë“œ")
    
    with gr.Row():
        upload_btn = gr.Button("ğŸ“¤ ì—…ë¡œë“œ & ìš”ì•½")
    
    with gr.Row():
        output_text = gr.Textbox(label="ğŸ“Œ ìš”ì•½ ê²°ê³¼", lines=30)

    # ì´ë²¤íŠ¸ ì—°ê²°
    model_update_btn.click(update_model, inputs=[model_info_input])
    model_load_btn.click(load_default_model, outputs=[model_info_input])

    system_update_btn.click(update_system_prompt, inputs=[system_prompt_input], outputs=[system_status])
    system_load_btn.click(load_default_system, outputs=[system_prompt_input])
    
    prompt_update_btn.click(update_prompt, inputs=[custom_prompt_input], outputs=[prompt_status])
    prompt_load_btn.click(load_default_prompt, outputs=[custom_prompt_input])
    
    upload_btn.click(parse_pdf_and_summarize, inputs=[pdf_upload], outputs=[output_text])
    


# ğŸ”¹ ì‹¤í–‰
if __name__ == "__main__":
    demo.launch(share=True)